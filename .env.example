# Database configuration
# Follow these instructions to install Milvus: https://milvus.io/docs/install_standalone-docker.md
# Once that's complete, proceed.

SERVER_PORT_NUMBER=3002
INTELLIGENCE_COLLECTION=intelligence
VOICE_COLLECTION=vocal
CHAT_COLLECTION=twitch_chat
MILVUS_URL=http://MILVUS_IP_HERE:19530
LLM_MODEL_TYPE=mistral

TWITCH_COMMAND_LIST=

# If you want your LLM to be augmented with existing knowledge, put it here.
# Read the documentation on how you should format the text files.

TEXT_DIRECTORY=./data
MAX_CHATS_TO_SAVE=30

# Use OpenRouter or OpenAI to augment the LLM's intelligence
# If you use your own backend with OpenAI Chat Completion endpoints, you can set the key to whatever you need to
# Models should be provided in the exact name they are specified from the API you are utilizing.
# If you'd like to utilize fast models at low cost, look into https://openrouter.ai

AUGMENT_WITH_LLM=true

SUMMARY_ENDPOINT=
SUMMARY_ENDPOINT_KEY_TYPE=oai
SUMMARY_API_KEY=
SUMMARY_MODEL=
SUMMARY_MODEL_TYPE=
SUMMARY_MODEL_MAX_TOKENS=128000

QUERY_ENDPOINT=
QUERY_API_KEY_TYPE=oai
QUERY_API_KEY=
QUERY_BUILDER_MODEL=
QUERY_MODEL_TYPE=
QUERY_MAX_TOKENS=8192


# If you want augment support, you'll need to sign up for a Brave Search API account.
# Do that here: https://brave.com/search/api/
# Once you do that, plug your API key here.

BRAVE_TOKEN=

# Optional: Get the weather so your LLM knows what the weather is outside.
# This requires your current coordinates. Get those at https://gps-coordinates.net
# Weather information will update every 15 minutes by the clock (e.g., 8:00, 8:15, 8:30, etc.)
# The OpenMateo weather API is free to use, and does not require a key.

WEATHER_ENABLED=true
WEATHER_LAT=
WEATHER_LONG=

# LLM API Paramters
# CHAT_COMPLETION_URL: Set this to the endpoint specified by your API provider. Usually <domain or IP with port number>/v1
# CHAT_COMPLETION_KEY: The API key of your Chat Completions provider.
# CHAT_COMPLETION_MODEL: The name of the model used with your provider.
# CHAT_COMPLETION_MAX_TOKENS: The max amount of tokens we should be sending this provider.


CHAT_COMPLETION_URL=
CHAT_COMPLETION_KEY_TYPE=local
CHAT_COMPLETION_KEY=
CHAT_COMPLETION_MODEL=
CHAT_COMPLETION_MAX_TOKENS=12288

# Embedding model
# This is how we turn words into funny numbers for database lookup later.
# Important for having dynamically switching context so your LLM responds faster.
# EMBEDDING_ENDPOINT: The URL or IP:Port combo to reach your embedding API
# EMBEDDING_API_KEY: The API key provided to you by your backend
# EMBEDDING_MODEL: The embedding model to use as provided by your backend.
# RERANKING_MODEL: The reranking model to use as provided by your backend.
# CLASSIFICATION_MODEL: The text classifier model to use as provided by your backend.

EMBEDDING_ENDPOINT=
EMBEDDING_API_KEY=lolno
EMBEDDING_API_KEY_TYPE=infinity
EMBEDDING_MODEL=
RERANKING_MODEL=
CLASSIFICATION_MODEL=

CONVERSION_ENDPOINT=
CONVERSION_API_KEY=
CONVERSION_API_KEY_TYPE=
CONVERSION_MODEL=
CONVERSION_MODEL_TYPE=
CONVERSION_MAX_TOKENS=

RERANK_STR_ENDPOINT=
RERANK_STR_API_KEY=
RERANK_STR_API_KEY_TYPE=
RERANK_STR_MODEL=
RERANK_STR_MODEL_TYPE=
RERANK_MAX_TOKENS=

AUTH_REQ=true

# LLM generation parameters
# Some of these may be ignored by an OpenAI-based API like OpenAI or OpenRouter.
# All of them will work with a backend like TabbyAPI, ArliRP, Oogabooga, or textgen-webui.

LLM_TOP_K=0
LLM_MAX_TOKENS=512
LLM_TOKEN_HEAL=false
LLM_TOP_P=1
LLM_TOP_A=0
LLM_TYPICAL_P=1
LLM_MIN_P=0.02
LLM_TEMP=0.5
LLM_DRY_LENGTH=2
LLM_DRY_BASE=1.75
LLM_DRY_MULTI=0.8
LLM_MIN_TOKENS=50
LLM_MIROSTAT=false
LLM_MIROSTAT_MODE=0
LLM_REP_PEN=1.0
LLM_BANNED_STRINGS=[]
LLM_XTC_THRESHOLD=0.1
LLM_XTC_PROB=0.2
LLM_SMOOTHING_FACTOR=0.2

# If you want your LLM to have a voice, edit these settings.
# We currently only support the AllTalkTTS backend, as it includes the full chain of XTTSv2 and RVC that makes convincing voices.
# TTS_ENABLED: whether or not your LLM will send its response to AllTalk after generation (generation typically takes ~2 additional seconds on an RTX 3090 if not using Low VRAM mode.) Can be 'true' or 'false'.
# ALLTALK_BASE: The URL or Port:IP combo that links to your AllTalkTTS instance

TTS_ENABLED=true
ALLTALK_BASE=